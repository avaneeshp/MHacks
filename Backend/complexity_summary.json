{
  "What is Complexity Analysis": "Complexity analysis is a method to evaluate the efficiency and scalability of algorithms. It focuses on understanding how the number of steps required by an algorithm changes as the input size grows, providing insights into an algorithm's performance characteristics.",
  "Metrics of Algorithm Complexity": "There are three primary metrics used to assess algorithm complexity: Best-Case (minimum steps for ideal input), Worst-Case (maximum steps for challenging input), and Average-Case (average steps over all possible inputs of a given size). These metrics provide a comprehensive view of an algorithm's potential performance under various scenarios.",
  "Factors Influencing Runtime": "Several factors can impact an algorithm's runtime, including the algorithm itself, implementation details (programmer skill), hardware specifications (CPU/memory speed), compiler optimizations, parallel processes, and the size of the input data. However, the focus of complexity analysis is primarily on the relationship between input size and the number of steps, as it reflects the algorithm's scalability.",
  "Measuring Input Size": "Input size is typically measured in terms of the number of elements (e.g., integers in an array) or the number of bits required to represent the input. Understanding the appropriate unit of measurement for input size is crucial for accurate complexity analysis.",
  "Big-O Notation": "Big-O notation is a mathematical representation used to describe the upper bound of an algorithm's growth rate. It provides a concise way to compare the efficiency of different algorithms and understand their scalability as input size increases.  For example, O(n) indicates linear growth, while O(n^2) signifies quadratic growth.",
  "Counting Steps": "To analyze an algorithm's complexity, we count the number of primitive operations it performs, such as variable assignments, arithmetic calculations, comparisons, array indexing, function calls, and returns. Each of these operations is assumed to take O(1) time, meaning their execution time is constant regardless of input size.",
  "Common Orders of Functions": "Several common orders of functions are used in complexity analysis, including constant (O(1)), logarithmic (O(log n)), linear (O(n)), loglinear (O(n log n)), quadratic (O(n^2)), polynomial (O(n^k)), exponential (O(c^n)), and factorial (O(n!)). Understanding these orders helps classify algorithms based on their growth rates.",
  "Amortized Complexity": "Amortized complexity deals with scenarios where an algorithm's performance is characterized by occasional expensive operations amidst a series of cheaper ones. It focuses on the average cost of an operation over a sequence, providing a more realistic assessment of the algorithm's overall efficiency.",
  "Balance Exercise": "The balance exercise demonstrates how different algorithms can be employed to solve the same problem with varying levels of efficiency. By analyzing the number of comparisons required to find a heavy ball among a set of billiard balls using a balance scale, we can illustrate the concepts of O(n^2), O(n), and O(log n) complexities." 
}
